{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "318075a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.functional import cross_entropy\n",
    "import os\n",
    "from thop import profile\n",
    "import pandas as pd\n",
    "import glob\n",
    "import math\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "import sys\n",
    "\n",
    "# 配置运行设备\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# 设置参数\n",
    "batch_size = 32\n",
    "learning_rate = 0.00003\n",
    "num_epoch = 50\n",
    "model_name = 'basenet'\n",
    "# only_train_fc = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b549cd64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据处理\n",
    "normalize = transforms.Normalize(mean=[0, 0, 0], std=[1, 1, 1])\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize([224, 224]),\n",
    "    transforms.ToTensor(),\n",
    "    normalize\n",
    "])\n",
    "\n",
    "# 读取图像数据\n",
    "train_dataset = ImageFolder('/kaggle/input/oral-cancer-dataset/Oral Cancer5/train/', transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_dataset = ImageFolder('/kaggle/input/oral-cancer-dataset/Oral Cancer5/test/', transform=transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "print('{0} for train. {1} for val'.format(len(train_dataset), len(test_dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485b8110",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Basenet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        '''\n",
    "        input_shape: [B, 3, 224, 224]\n",
    "\n",
    "        '''\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        self.conv_layer1 = nn.Conv2d(3, 16, 5, stride=1, padding=2)\n",
    "        self.conv_layer2 = nn.Conv2d(16, 32, 3, stride=1, padding=1)\n",
    "        self.conv_layer3 = nn.Conv2d(32, 64, 3, stride=1, padding=1)\n",
    "        self.conv_layer4 = nn.Conv2d(64, 128, 3, stride=1, padding=1)\n",
    "        self.conv_layer5 = nn.Conv2d(128, 256, 3, stride=1, padding=1)\n",
    "        self.conv_layer6 = nn.Conv2d(256, 512, 3, stride=1, padding=1)\n",
    "        self.inception = nn.Conv2d(32, 128, 3, stride=1, padding=1)\n",
    "        self.conv_layer_res = nn.Conv2d(128, 128, 3, stride=1, padding=1)\n",
    "\n",
    "        \n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.adptavgpool2d = torch.nn.AdaptiveAvgPool2d(output_size=(1, 1))\n",
    "        self.fc = nn.Linear(512, 2, bias=True)\n",
    "        self.flatten = nn.Flatten(start_dim=1, end_dim=-1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        args:\n",
    "            x: Input img, (B, 3, 224, 224)\n",
    "        return:\n",
    "            the calss capsules, ench capsule is a 16 dimension vector\n",
    "\n",
    "        \"\"\"\n",
    "        x = self.relu(self.conv_layer1(x))  # [B, 16, 224, 224]\n",
    "        x = self.maxpool(x)# [B, 16, 112, 112]\n",
    "        x = self.relu(self.conv_layer2(x))\n",
    "        y = self.maxpool(x)# [B, 32, 56, 56]\n",
    "        \n",
    "        \n",
    "        x = self.relu(self.conv_layer3(y))\n",
    "        x = self.maxpool(x) # [B, 64, 28, 28]\n",
    "        x = self.conv_layer4(x) # [B, 128, 28, 28]\n",
    "        \n",
    "        y = self.inception(y) # [B, 128, 56, 56]\n",
    "        y = self.maxpool(self.conv_layer_res(y)) # [B, 128, 28, 28]\n",
    "        \n",
    "        x = self.relu(x + y)\n",
    "        x = self.maxpool(x) # [B, 128, 14, 14]\n",
    "        x = self.relu(self.conv_layer5(x)) # [B, 256, 14, 14]\n",
    "        x = self.maxpool(x)\n",
    "        x = self.relu(self.conv_layer6(x)) # [B, 512, 7, 7]\n",
    "        \n",
    "        x = self.adptavgpool2d(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa5f244",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_model_path = '/kaggle/input/oral-cancer-dataset/breakhis/basenet/best/basenet-oral_epoch65.pth'\n",
    "save_path = '/kaggle/working/check_point'\n",
    "if not os.path.exists(save_path):\n",
    "    os.mkdir(save_path)\n",
    "result_path = os.path.join('/kaggle/working/check_point', model_name)\n",
    "if not os.path.exists(result_path):\n",
    "    print(1)\n",
    "    os.mkdir(result_path)\n",
    "if len(glob.glob(result_path + '/**.pth')) == 0:\n",
    "    model = torch.load(pretrained_model_path)\n",
    "else:\n",
    "    model_path = glob.glob(result_path + '/**.pth')[-1]\n",
    "    model = torch.load(model_path)\n",
    "# if only_train_fc:\n",
    "#     for param in model.parameters():\n",
    "#         param.requires_grad_(False)\n",
    "#     for param in model.fc.parameters():\n",
    "#         param.requires_grad_(True)\n",
    "\n",
    "train_test_data_path = os.path.join(result_path, 'train_test_data.csv')\n",
    "if os.path.exists(train_test_data_path):\n",
    "    train_test_data = pd.read_csv(train_test_data_path)\n",
    "    last_epoch = train_test_data.shape[0]\n",
    "    test_acc_best = train_test_data['test_acc_best'].values[-1]\n",
    "else:\n",
    "    train_test_data = pd.DataFrame(data=[], columns=['train_acc', 'train_loss',\n",
    "                                                     'train_lr',\n",
    "                                                     'test_acc', 'test_loss', \n",
    "                                                     'epoch', 'test_acc_best'])\n",
    "    last_epoch = 0\n",
    "    test_acc_best = 0\n",
    "assert num_epoch > last_epoch, '已达训练次数'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "341bea6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)\n",
    "# 输出模型参数与模型计算量\n",
    "\n",
    "flops, params = profile(model, inputs=(torch.zeros((batch_size, 3, 224, 224)).to(device),), verbose=False)\n",
    "print(f'number of parameter: {params}', ', %.1f GFLOPS' % (flops / 1E9 * 2))\n",
    "\n",
    "def get_parameter_number(model):\n",
    "    total_num = sum(p.numel() for p in model.parameters())\n",
    "    trainable_num = sum(p.numel() for p in model.parameters()if p.requires_grad)\n",
    "    return {'Total': total_num, 'Trainable': trainable_num}\n",
    "print(get_parameter_number(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "464f27a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "loss_fn = torch.nn.CrossEntropyLoss(reduction='sum')\n",
    "\n",
    "\n",
    "def train(epoch, dataloder):\n",
    "    model.train()\n",
    "\n",
    "    t0 = time.time()\n",
    "    for (X_batch, y_batch) in tqdm(dataloder, leave=False, desc=f'epoch:{epoch}'):\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        out_put = model(X_batch)\n",
    "        loss = loss_fn(out_put, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    now_lr = optimizer.param_groups[0][\"lr\"]\n",
    "#     scheduler.step()\n",
    "    t1 = time.time()\n",
    "    print(f'epoch[{epoch}] time[{round(t1 - t0, 1)}]s lr:{now_lr}')\n",
    "    return now_lr\n",
    "\n",
    "def evaluate(data_loader, type):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        eval_loss = 0\n",
    "        for images, labels in data_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(F.softmax(outputs, dim=-1), 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            eval_loss += loss_fn(outputs, labels).item()\n",
    "    acc = 100 * correct / total\n",
    "    print(f'Accuracy on {type} set: {round(acc, 2)}%  eval_loss:{eval_loss / total}')\n",
    "    return acc, eval_loss / total\n",
    "\n",
    "\n",
    "'''\n",
    "每次运行之后要保存：\n",
    "1.模型本身\n",
    "2.模型迭代次数\n",
    "3.模型学习率\n",
    "4.历代模型表现情况loss,acc等\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    weight_path_best = os.path.join(result_path, 'best')\n",
    "    if not os.path.exists(weight_path_best):\n",
    "        os.mkdir(weight_path_best)\n",
    "    for epoch in range(last_epoch, num_epoch):\n",
    "        weight_name = '{}-oral'.format(model_name)\n",
    "        lr = train(epoch, train_loader)\n",
    "        train_acc, train_loss = evaluate(train_loader, type='train')\n",
    "        test_acc, test_loss = evaluate(test_loader, type='test')\n",
    "        \n",
    "        # 保存训练好的模型之前，删掉已有的模型\n",
    "        for f in glob.glob(result_path + '/**.pth'):\n",
    "            os.remove(f)\n",
    "        weight_name = weight_name + '_epoch{}.pth'.format(epoch + 1)\n",
    "        weight_path = os.path.join(result_path, weight_name)\n",
    "        torch.save(model, weight_path)\n",
    "        \n",
    "        if test_acc > test_acc_best:\n",
    "            test_acc_best = test_acc\n",
    "            for f in glob.glob(weight_path_best + '/**.pth'):\n",
    "                os.remove(f)\n",
    "            torch.save(model, os.path.join(weight_path_best, weight_name))\n",
    "        train_test_data.loc[len(train_test_data.index)] = [train_acc, train_loss,\n",
    "                                                           lr,\n",
    "                                                           test_acc, test_loss,\n",
    "                                                           epoch, test_acc_best]\n",
    "\n",
    "        train_test_data.to_csv(train_test_data_path, index=False)\n",
    "\n",
    "    train_acc_array = train_test_data['train_acc'].values\n",
    "    test_acc_array = train_test_data['test_acc'].values\n",
    "    train_loss_array = train_test_data['train_loss'].values\n",
    "    test_loss_array = train_test_data['test_loss'].values\n",
    "\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.subplot(2, 1, 1)\n",
    "    plt.plot(train_acc_array, label='Training Accuracy')\n",
    "    plt.plot(test_acc_array, label='Validation Accuracy')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Capsnet Training and Validation Accuracy')\n",
    "\n",
    "    plt.subplot(2, 1, 2)\n",
    "    plt.plot(train_loss_array, label='Training Loss')\n",
    "    plt.plot(test_loss_array, label='Validation Loss')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.ylabel('Margin Entropy')\n",
    "    plt.title('Capsnet Training and Validation Loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
